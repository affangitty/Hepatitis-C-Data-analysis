{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7436075c",
   "metadata": {},
   "source": [
    "# Hepatitis C Data Analysis\n",
    "\n",
    "**Author:** Affan Ahammed\n",
    "\n",
    "full analysis: EDA, preprocessing, KMeans clustering, PCA, visualizations, saving outputs, and a final summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Setup: install (optional) and imports\n",
    "# Uncomment the pip installs if running in a fresh Colab environment\n",
    "# !pip install --quiet pandas matplotlib scikit-learn seaborn scipy\n",
    "\n",
    "import os, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy import stats\n",
    "\n",
    "# Output directory\n",
    "OUT_DIR = \"analysis_outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print('Environment ready. Outputs will be saved to', OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b3970b",
   "metadata": {},
   "source": [
    "## 2) Load dataset\n",
    "Load CSV from the GitHub link provided in the project instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Load dataset\n",
    "GITHUB_CSV = \"https://raw.githubusercontent.com/salemprakash/EDA/main/Data/HepatitisCdata.csv\"\n",
    "df = pd.read_csv(GITHUB_CSV)\n",
    "print('Raw shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ef108",
   "metadata": {},
   "source": [
    "## 3) Quick EDA\n",
    "Show data types and missing values per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Quick EDA\n",
    "print(df.info())\n",
    "print('\\nMissing values per column:\\n', df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab51f1",
   "metadata": {},
   "source": [
    "## 4) Clean trivial columns\n",
    "Drop fully empty columns and 'Unnamed' index cols; select numeric columns for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Drop empty / unnamed columns and select numeric features\n",
    "df = df.dropna(axis=1, how='all')\n",
    "for col in df.columns:\n",
    "    if col.startswith('Unnamed'):\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print('Numeric columns (count):', len(numeric_cols))\n",
    "numeric_cols[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7639419f",
   "metadata": {},
   "source": [
    "## 5) Imputation\n",
    "Impute missing numeric values using column means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401506cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Mean imputation for numeric columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_num = pd.DataFrame(imputer.fit_transform(df[numeric_cols]), columns=numeric_cols)\n",
    "print('Any NaNs after imputation?', df_num.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c55065",
   "metadata": {},
   "source": [
    "## 6) Outlier detection\n",
    "Compute z-scores and report number of extreme rows (z > 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Outlier detection (z-score)\n",
    "z_scores = np.abs(stats.zscore(df_num, nan_policy='omit'))\n",
    "outlier_mask = (z_scores > 4).any(axis=1)\n",
    "print('Number of extreme rows (z>4):', outlier_mask.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c90b031",
   "metadata": {},
   "source": [
    "## 7) Winsorization\n",
    "Clip each numeric column to [1st percentile, 99th percentile] to reduce extreme outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17693588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Winsorize/clipping\n",
    "def winsorize_df(df_in):\n",
    "    df_out = df_in.copy()\n",
    "    for col in df_out.columns:\n",
    "        lower_q = df_out[col].quantile(0.01)\n",
    "        upper_q = df_out[col].quantile(0.99)\n",
    "        df_out[col] = df_out[col].clip(lower_q, upper_q)\n",
    "    return df_out\n",
    "\n",
    "df_wins = winsorize_df(df_num)\n",
    "df_wins.describe().T[['mean','std','min','25%','50%','75%','max']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8fb649",
   "metadata": {},
   "source": [
    "## 8) Scaling\n",
    "Standardize the winsorized features with StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ada78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_wins)\n",
    "scaled_df = pd.DataFrame(X_scaled, columns=df_wins.columns)\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19035d32",
   "metadata": {},
   "source": [
    "## 9) Save scaled features\n",
    "Save the scaled features as CSV for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6202070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Save scaled dataframe\n",
    "scaled_df.to_csv(os.path.join(OUT_DIR, 'scaled_features.csv'), index=False)\n",
    "print('Saved scaled_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3072ffc0",
   "metadata": {},
   "source": [
    "## 10) Elbow and Silhouette Analysis\n",
    "Compute inertia and silhouette score for k in [2..7], plot elbow and silhouette charts (inline) and save PNG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37feb82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Elbow + silhouette analysis\n",
    "def elbow_scores(X, k_range=range(2,8)):\n",
    "    inertias = []\n",
    "    sil_scores = []\n",
    "    for k in k_range:\n",
    "        km = KMeans(n_clusters=k, n_init=20, random_state=RANDOM_STATE)\n",
    "        labels_k = km.fit_predict(X)\n",
    "        inertias.append(km.inertia_)\n",
    "        sil_scores.append(silhouette_score(X, labels_k))\n",
    "    return inertias, sil_scores\n",
    "\n",
    "k_range = range(2,8)\n",
    "inertias, sil_scores = elbow_scores(X_scaled, k_range=k_range)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(list(k_range), inertias, '-o')\n",
    "plt.title('Elbow: Inertia vs k'); plt.xlabel('k'); plt.ylabel('Inertia'); plt.grid(True)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(list(k_range), sil_scores, '-o')\n",
    "plt.title('Silhouette Score vs k'); plt.xlabel('k'); plt.ylabel('Silhouette score'); plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, 'elbow_silhouette.png'), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "print('Silhouette scores:', dict(zip(k_range, [round(s,3) for s in sil_scores])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef1add",
   "metadata": {},
   "source": [
    "## 11) KMeans clustering\n",
    "Choose k (3) and run KMeans with multiple inits; compute silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ff0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) KMeans with chosen k=3\n",
    "k_opt = 3\n",
    "kmeans = KMeans(n_clusters=k_opt, n_init=50, random_state=RANDOM_STATE)\n",
    "cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "sil_score = silhouette_score(X_scaled, cluster_labels)\n",
    "print(f'Chosen k = {k_opt}, silhouette score = {sil_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8397b55",
   "metadata": {},
   "source": [
    "## 12) Attach cluster labels\n",
    "Append cluster labels to original dataframe and save CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c2167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Append cluster labels and save\n",
    "df_out = df.copy()\n",
    "df_out['cluster'] = cluster_labels\n",
    "# If the original has any string labels, keep them; otherwise this is fine\n",
    "df_out.to_csv(os.path.join(OUT_DIR, 'data_with_clusters.csv'), index=False)\n",
    "print('Saved data_with_clusters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c980a62d",
   "metadata": {},
   "source": [
    "## 13) Cluster profiling\n",
    "Compute mean and std per cluster for numeric columns; save as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd709726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) Cluster profiling\n",
    "cluster_profile = df_out.groupby('cluster')[numeric_cols].agg(['mean','std','count']).round(3)\n",
    "cluster_profile.to_csv(os.path.join(OUT_DIR, 'cluster_profile.csv'))\n",
    "cluster_profile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f6116",
   "metadata": {},
   "source": [
    "## 14) PCA\n",
    "Fit PCA with 2 components for visualization and report explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973881be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) PCA (2 components)\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "pcs = pca.fit_transform(X_scaled)\n",
    "print('Explained variance ratio (2 components):', pca.explained_variance_ratio_, 'sum =', pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ce6b45",
   "metadata": {},
   "source": [
    "## 15) PCA scatter plot\n",
    "Plot PCA projected points colored by cluster; save PNG and display inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dfcdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15) PCA scatter colored by cluster\n",
    "pc_df = pd.DataFrame(pcs, columns=['PC1','PC2'])\n",
    "pc_df['cluster'] = cluster_labels\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(data=pc_df, x='PC1', y='PC2', hue='cluster', palette='tab10', s=60, alpha=0.9)\n",
    "plt.title('PCA (2 components) colored by KMeans cluster')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% var)'); plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% var)')\n",
    "plt.legend(title='cluster', loc='best')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, 'pca_clusters.png'), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a251d50",
   "metadata": {},
   "source": [
    "## 16) PCA with true labels (if available)\n",
    "If dataset contains a ground-truth label column, visualize it for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9481ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16) PCA colored by true label if present\n",
    "possible_label_cols = ['Category','Class','Label','Stage']\n",
    "label_col = None\n",
    "for c in possible_label_cols:\n",
    "    if c in df.columns:\n",
    "        label_col = c\n",
    "        break\n",
    "\n",
    "if label_col:\n",
    "    pc_df['true_label'] = df[label_col].values\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(data=pc_df, x='PC1', y='PC2', hue='true_label', palette='tab20', s=60, alpha=0.9)\n",
    "    plt.title('PCA colored by true label')\n",
    "    plt.xlabel('PC1'); plt.ylabel('PC2')\n",
    "    plt.legend(title='true_label', bbox_to_anchor=(1.05,1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUT_DIR, 'pca_true_labels.png'), dpi=200)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No common label column found. Skipping this plot.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381f0761",
   "metadata": {},
   "source": [
    "## 17) Summary statistics for selected features\n",
    "Select a few key features (or fallback to first 3 numeric) and save means/stds per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17) Summary stats for representative features\n",
    "features_of_interest = ['Bilirubin','ALT','AST']\n",
    "existing = [f for f in features_of_interest if f in numeric_cols]\n",
    "if len(existing) < 1:\n",
    "    existing = numeric_cols[:3]\n",
    "summary = df_out.groupby('cluster')[existing].agg(['mean','std','count']).round(3)\n",
    "summary.to_csv(os.path.join(OUT_DIR, 'cluster_summary_selected_features.csv'))\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f43de",
   "metadata": {},
   "source": [
    "## 18) Save KMeans model\n",
    "Persist the trained KMeans model to disk using pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e19e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18) Save KMeans model\n",
    "with open(os.path.join(OUT_DIR, 'kmeans_model.pkl'), 'wb') as f:\n",
    "    pickle.dump(kmeans, f)\n",
    "print('Saved kmeans_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5197d3",
   "metadata": {},
   "source": [
    "## 19) Final metrics and cluster sizes\n",
    "Print silhouette, chosen k, and sizes of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea52265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19) Final metrics\n",
    "print('FINAL METRICS')\n",
    "print('Chosen k:', k_opt)\n",
    "print('Silhouette score:', round(sil_score,4))\n",
    "for i in range(k_opt):\n",
    "    cnt = int((cluster_labels==i).sum())\n",
    "    print(f'Cluster {i}: size = {cnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97686d48",
   "metadata": {},
   "source": [
    "## 20) Boxplots for selected features by cluster\n",
    "Create boxplots for selected features and save PNG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c81992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20) Boxplots (selected features)\n",
    "features_plot = existing if 'existing' in globals() and len(existing)>0 else df_wins.columns[:3].tolist()\n",
    "plt.figure(figsize=(12,4))\n",
    "for i, col in enumerate(features_plot,1):\n",
    "    plt.subplot(1, len(features_plot), i)\n",
    "    sns.boxplot(x=df_out['cluster'], y=df_out[col])\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUT_DIR, 'boxplots_by_cluster.png'), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23f335",
   "metadata": {},
   "source": [
    "## 21) Save quick textual summary\n",
    "Save a short analysis_summary.txt summarizing chosen k, silhouette, cluster sizes and list saved files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21) Save summary text file\n",
    "with open(os.path.join(OUT_DIR, 'analysis_summary.txt'), 'w') as f:\n",
    "    f.write('Hepatitis C Data Analysis\\n')\n",
    "    f.write(f'Chosen k: {k_opt}\\n')\n",
    "    f.write(f'Silhouette score: {round(sil_score,4)}\\n')\n",
    "    f.write('Cluster sizes:\\n')\n",
    "    for i in range(k_opt):\n",
    "        f.write(f'  Cluster {i}: {int((cluster_labels==i).sum())}\\n')\n",
    "    f.write('\\nSaved files in this folder:\\n')\n",
    "    for fname in sorted(os.listdir(OUT_DIR)):\n",
    "        f.write('  ' + fname + '\\n')\n",
    "\n",
    "print('Saved analysis_summary.txt and listed files:')\n",
    "print('\\n'.join(sorted(os.listdir(OUT_DIR))))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
